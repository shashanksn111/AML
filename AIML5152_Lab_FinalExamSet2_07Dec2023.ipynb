{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reg Num:  _______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "$$\\color{orange}{AML\\ 5152\\,\\lvert\\, Applied\\ Machine\\ Learning\\,\\lvert\\,Lab\\ Final\\,\\lvert\\,Odd\\ Semester\\ 2023}$$\n",
    "---\n",
    "\n",
    "**Instructions:**\n",
    "1. Fill the reg num at the top of this notebook\n",
    "2. When a code template is provided, you have to fill the code template. You should not replace the code template with different code from elsewhere\n",
    "3. Upload your Jupyter notebook with all its outputs intact here: https://tinyurl.com/tckf29w4\n",
    "4. Do not solicit inputs from others. Plagiarism check will be performed after the exam\n",
    "5. You will be orally asked why you did each design choice along the way. If you cannot defend your choice, then some marks will be deducted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem Statement**\n",
    "\n",
    "**PS: DO NOT FORGET TO TRAIN-TEST SPLIT AT AN APPROPRIATE TIME IN THE ENTIRE FLOW**.\n",
    "\n",
    "You decide where you want to position the train test split in the stages below\n",
    "\n",
    "#### I. Create a pandas dataset for apples satisfying the following constraints:\n",
    "1. Datset should have six columns - weight, volume, pesticide per apple, discoloration, machine_plucked and apple_type and 100 records with 70 Gala apples, 15 Fuji apples and 15 Red apples\n",
    "2. Apple type is a target variable. Remaining are predictor variables. \n",
    "3. There are 3 apple types: Gala, Fuji, Red. \n",
    "4. Machine Plucked is either yes or no.\n",
    "5. Simulate the data randomly such that subsequent simulations produce very similar or identical data \n",
    "6. Simulate the data for the 3 types of apples according to the following rules:\n",
    "\t* Gala apple weights are normally distributed with mean of 155 g and a standard deviation of 5 g.\n",
    "\t* Fuji apple weights are uniformly distributed between 200 and 250 gram\n",
    "\t* Red apple weights are distributed according to triangular distribution with minimum weight of 100g, maximum weight of 190 g and the most frequent weight being 170g\n",
    "7. Apple volumes are normally distributed for the three apple types Gala, Fuji and Red with a mean of 187cc, 270cc and 150cc respectively and variance of 25cc respectively\n",
    "8. A pesticide Quinalphos was dissolved in water and sprayed at the rate of 500 gm per 100 apples. The spray was unequal and had a variance of 4 milligram per apple. This pestiside dosage is common to all three apple types. This data will be used to populate \"pesticide per apple\" feature\n",
    "9. Discoloration of the apple is equal to the percentile of the pesticide per apple\n",
    "\n",
    "#### II. Introduce NaNs\n",
    "1. Randomly introduce NaN for weight and volume feature for 25% of the records such that the **fraction of NaN for each apple type is proportional to the ratio of samples**.\n",
    "2. Pesticide_per_apple data should be randomly nulled out for data beyond 75th percentile\n",
    "3. Randomly introduce NaN for machine plucked apples for 5% of records\n",
    "4. Randomly introduce NaN for apple type for 10% of records\n",
    "\n",
    "#### III Transform, Train/Test Split and Impute\n",
    "Ask yourself these questions and do accordingly: \n",
    "1. Will you do train test split before or after doing train test split? \n",
    "2. Will you do transformation after imputation or before? \n",
    "3. Will you do split before transformation?\n",
    "\n",
    "According to your choice do these three in the order you deem fit\n",
    "\n",
    "1. Impute the data for relevant columns using an appropriate imputation method fit for each scenario\n",
    "2. If there are any records that you feel should be deleted, then please do so\n",
    "3. Do a train test split 80:20 such that the fraction of NaN for each apple type is proportional to the ratio of samples of that apple type\n",
    "4. Do any other data transformation you feel is needed\n",
    "\n",
    "#### IV Feature Elimination and Feature Selection\n",
    "1. If there are any features that you can immediately drop without any exploration, programming then please do so first\n",
    "2. Check which features have highest predictive power wrt target variable\n",
    "3. Check features on which target is dependent. Use a mechanism that is different from previous method for this.\n",
    "4. Base on the above two checks, choose 2 features for predicting apple type\n",
    "\n",
    "#### V ML Prediction\n",
    "1. Apply Logistic Regression to predict apple type\n",
    "2. Choose a  metric that you think is most suitable for this scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "#### I. Create a pandas dataset for apples satisfying the following constraints:\n",
    "1. Datset should have six columns - weight, volume, pesticide per apple, discoloration, machine_plucked and apple_type and 200 records with 70 Gala apples, 15 Fuji apples and 15 Red apples\n",
    "2. Apple type is a target variable. Remaining are predictor variables. \n",
    "3. There are 3 apple types: Gala, Fuji, Red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records = 100\n",
    "apple_types = [\"Gala\", \"Fuji\", \"Red\"]\n",
    "apple_ratios = (0.7, 0.15, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Machine Plucked is either yes or no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_plucked = np.random.choice(['Yes', 'No'], total_records, p=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulate Gala apples**\n",
    "\n",
    "1. Gala apple weights are normally distributed with mean of 155 g and a standard deviation of 5 g.\n",
    "2. Gala apple volumes are normally distributed with mean of 187 cc and variance of 25 cc $^2$\n",
    "\n",
    "**Note: Check if the np.random functions accept standard deviation or variance as arguments and accordingly adjust**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Gala(Enum):\n",
    "    apple_ratio = 0.7\n",
    "    \n",
    "    volume_avg = 187\n",
    "    volume_variance = 25\n",
    "\n",
    "    weight_mean = 155\n",
    "    weight_standard_dev = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gala_weights = np.random.?(Gala.weight_mean.value, \n",
    "                                Gala.?.?, \n",
    "                                Gala.?.?*total_records)\n",
    "\n",
    "gala_volumes = np.random.?(size=int(Gala.?.? * ?), \n",
    "                                scale=sqrt(Gala.?.?),\n",
    "                                loc=Gala.?.?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulate Fuji apples**\n",
    "\n",
    "1. Fuji apple weights are uniformly distributed between 200 and 250 gram\n",
    "2. Fuji apple volumes are normally distributed with a mean os 270 cc and variance of 25 cc $^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuji_dict = {\n",
    "    \"apple_ratio\": 0.15,\n",
    "    \"volume_mean\": 270,\n",
    "    \"volume_variance\": 25,\n",
    "    \"weight_high\": 250,\n",
    "    \"weight_low\": 200\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuji_weights = np.random.?(size=int(fuji_dict[?] * ?),\n",
    "                                 high=fuji_dict[?],\n",
    "                                 low=fuji_dict[?])\n",
    "\n",
    "fuji_volumes = np.random.?(size=int(fuji_dict[?] * ?), \n",
    "                                scale=sqrt(fuji_dict[?]),\n",
    "                                loc=?[\"volume_mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulate Red Apples**\n",
    "\n",
    "\n",
    "1. Red apple weights are distributed according to triangular distribution with minimum weight of 100g, maximum weight of 190 g and the most frequent weight being 170g\n",
    "2. Red apple volumes are normally distributed with mean of 150cc and standard deviation of 5cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_weights = np.random.triangular(100, 170, 190, 15)\n",
    "red_volumes = np.random.?(size=int(0.15*total_records), scale=150, loc=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. A pesticide Quinalphos was dissolved in water and sprayed at the rate of 500 gm per 100 apples. The spray was unequal and had a variance of 4 milligram per apple. This pestiside dosage is common to all three apple types. This data will be used to populate \"pesticide per apple\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.90228722 6.91854165 9.30636492 3.46530487 6.74464127 5.36668401\n",
      " 9.37960587 3.38340343 3.32055632 3.80121471 0.75220855 3.94848996\n",
      " 3.48173468 5.30078757 5.68351195 8.75234168 6.90084768 3.84619269\n",
      " 3.20317066 5.98383834 2.35953359 8.66291753 7.35888024 4.0616487\n",
      " 1.57373094 7.70774475 4.77092031 7.47563262 1.81114468 3.80124995\n",
      " 5.0104874  5.09396119 4.09986906 6.24569986 2.86475914 4.71524103\n",
      " 5.24059126 6.02887767 6.42322976 2.75071582 1.93177166 7.55535364\n",
      " 5.66462802 3.50302693 8.10230395 5.23134927 7.35859437 5.13503696\n",
      " 9.12149585 8.51068168 4.5020717  6.9431419  6.2907519  7.73726312\n",
      " 3.07015308 6.37210292 7.11684897 1.48252103 2.63348297 0.92153564\n",
      " 4.46118633 6.43508451 8.0047141  5.14818956 8.25723109 2.23979708\n",
      " 1.59323512 4.8889046  5.7681309  4.9346105  0.8651158  4.82175992\n",
      " 2.391061   6.3393451  5.73319649 3.12024043 3.97226617 2.88157296\n",
      " 4.87464181 6.91028464 3.02854791 6.00809303 3.93948476 3.41425434\n",
      " 4.78593928 2.92951536 3.89270139 2.60424421 8.92945027 5.0705271\n",
      " 3.60054898 5.42795982 4.7753439  4.5580608  6.2283334  6.51501542\n",
      " 3.9389977  3.84836352 4.44989661 0.39615767]\n"
     ]
    }
   ],
   "source": [
    "#pesticide_per_apple = np.random.normal(50/total_records, 3, total_records) \n",
    "\n",
    "from scipy import stats\n",
    "pesticide_per_apple_distribution = stats.norm(\n",
    "    loc=500/total_records, \n",
    "    scale=?\n",
    ")\n",
    "pesticide_per_apple = pesticide_per_apple_distribution.rvs(size=total_records)\n",
    "print(pesticide_per_apple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.926630062105628, 0.8312888358220992, 0.9843478290983501, 0.2214374482690769, 0.8084832587081733, 0.5727351614315366, 0.9857307340373052, 0.20945944468049693, 0.2005321821933025, 0.2744555400987607, 0.016839432006494345, 0.29952921459875403, 0.22388660138904837, 0.5597730284041454, 0.6337327284952862, 0.9696840875471561, 0.8290515319423867, 0.282002270471181, 0.18448225881795993, 0.6886117576099438, 0.09337858409518196, 0.966483951563132, 0.8808885164240854, 0.3194720437483427, 0.043343896480428155, 0.9121114507246151, 0.45440493113897107, 0.8921079106663193, 0.05542014078510172, 0.2744614145163289, 0.502091923936583, 0.5187356528099304, 0.32633161640210984, 0.7333084289311411, 0.1428458822254438, 0.4433901329369875, 0.547875517812965, 0.6965273928722624, 0.761648354314821, 0.1303703647849549, 0.06250078385638944, 0.8993182995033568, 0.6301739197437303, 0.22708337146196406, 0.9395673660474344, 0.5460447949114474, 0.8808600704160591, 0.5269155252202345, 0.9803364525519929, 0.9603994878227453, 0.4016942568680952, 0.8343679800387547, 0.7406582074374212, 0.9144427628238865, 0.16729157484167706, 0.7536596707544734, 0.8550690196642847, 0.039310883637880406, 0.11835335480087927, 0.02071343043974732, 0.39380831370184155, 0.7634802134893851, 0.933497539134854, 0.5295325157659839, 0.9483027843679362, 0.08377770419007813, 0.04424826091621905, 0.4778510651790986, 0.6495350304844695, 0.4869590060338307, 0.019346257349626684, 0.46449325576715483, 0.09603677597930177, 0.7484667226077346, 0.6430406416588541, 0.17363961343683165, 0.30367251932509565, 0.1447512741244858, 0.4750110213092317, 0.8302471350942187, 0.16213378225572322, 0.6928856549667947, 0.2979666635183928, 0.21392595864967118, 0.4573824471642464, 0.15027787915493085, 0.28990943783912027, 0.11548227871539302, 0.9752769702914926, 0.5140652067217425, 0.24204937166598145, 0.5847186383655424, 0.4552816510515107, 0.41255805197490025, 0.7304474120827585, 0.775627125744453, 0.29788225677219504, 0.28236902147731135, 0.39163826040702054, 0.01066980920642659]\n"
     ]
    }
   ],
   "source": [
    "discoloration = [pesticide_per_apple_distribution.cdf(rec) for rec in pesticide_per_apple]\n",
    "print(discoloration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the discoloration into percentage and only integer precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate all features and target variables and make the dataframe**\n",
    "\n",
    "1. Be sure to line up the simulated records per the apple type and concatenate\n",
    "2. Display the final dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### II. Introduce NaNs\n",
    "1. Randomly introduce NaN for weight and volume feature for 25% of the records such that the **fraction of NaN for each apple type is proportional to the ratio of samples**.\n",
    "2. Pesticide_per_apple data should be randomly nulled out for data beyond 75th percentile. Use the discoloration data (which is nothing but the percentile) to make this determination\n",
    "3. Randomly introduce NaN for machine plucked apples for 5% of records\n",
    "4. Randomly introduce NaN for apple type for 10% of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### III Transform, Train/Test Split and Impute\n",
    "Ask yourself these questions and do accordingly: \n",
    "1. Will you do train test split before or after doing train test split? \n",
    "2. Will you do transformation after imputation or before? \n",
    "3. Will you do split before transformation?\n",
    "\n",
    "According to your choice do these three in the order you deem fit\n",
    "\n",
    "1. Impute the data for relevant columns using an appropriate imputation method fit for each scenario\n",
    "2. If there are any records that you feel should be deleted, then please do so\n",
    "3. Do a train test split 80:20 such that the fraction of NaN for each apple type is proportional to the ratio of samples of that apple type\n",
    "4. Do any other data transformation you feel is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### IV Feature Elimination and Feature Selection\n",
    "1. If there are any features that you can immediately drop without any exploration, programming then please do so first\n",
    "2. Check which features have highest predictive power wrt target variable\n",
    "3. Check features on which target is dependent. Use a mechanism that is different from previous method for this.\n",
    "4. Base on the above two checks, choose 2 features for predicting apple type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### V ML Prediction\n",
    "1. Apply Logistic Regression to predict apple type\n",
    "2. Choose a  metric that you think is most suitable for this scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quickstart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
